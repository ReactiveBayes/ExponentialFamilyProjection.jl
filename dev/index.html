<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · ExponentialFamilyProjection.jl</title><meta name="title" content="Home · ExponentialFamilyProjection.jl"/><meta property="og:title" content="Home · ExponentialFamilyProjection.jl"/><meta property="twitter:title" content="Home · ExponentialFamilyProjection.jl"/><meta name="description" content="Documentation for ExponentialFamilyProjection.jl."/><meta property="og:description" content="Documentation for ExponentialFamilyProjection.jl."/><meta property="twitter:description" content="Documentation for ExponentialFamilyProjection.jl."/><meta property="og:url" content="https://reactivebayes.github.io/ExponentialFamilyProjection.jl/"/><meta property="twitter:url" content="https://reactivebayes.github.io/ExponentialFamilyProjection.jl/"/><link rel="canonical" href="https://reactivebayes.github.io/ExponentialFamilyProjection.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>ExponentialFamilyProjection.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Projection-parameters"><span>Projection parameters</span></a></li><li><a class="tocitem" href="#Projection-family"><span>Projection family</span></a></li><li><a class="tocitem" href="#Projection"><span>Projection</span></a></li><li><a class="tocitem" href="#opt-strategies"><span>Optimization strategies</span></a></li><li><a class="tocitem" href="#In-place-logpdf/grad/Hessian-adapters"><span>In-place logpdf/grad/Hessian adapters</span></a></li><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li><li><a class="tocitem" href="#Other"><span>Other</span></a></li><li><a class="tocitem" href="#Manopt-extensions"><span>Manopt extensions</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="github.com/ReactiveBayes/ExponentialFamilyProjection.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ExponentialFamilyProjection"><a class="docs-heading-anchor" href="#ExponentialFamilyProjection">ExponentialFamilyProjection</a><a id="ExponentialFamilyProjection-1"></a><a class="docs-heading-anchor-permalink" href="#ExponentialFamilyProjection" title="Permalink"></a></h1><p>The <code>ExponentialFamilyProjection.jl</code> package offers a suite of functions for projecting an arbitrary (un-normalized) log probability density function onto a specified member of the exponential family (e.g., Gaussian, Beta, Bernoulli). This is achieved by optimizing the natural parameters of the exponential family member within a defined manifold. The library leverages <code>Manopt.jl</code> for optimization and utilizes <a href="https://github.com/ReactiveBayes/ExponentialFamilyManifolds.jl"><code>ExponentialFamilyManifolds.jl</code></a> to define the manifolds corresponding to the members of the exponential family.</p><h2 id="Projection-parameters"><a class="docs-heading-anchor" href="#Projection-parameters">Projection parameters</a><a id="Projection-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Projection-parameters" title="Permalink"></a></h2><p>In order to project a log probability density function onto a member of the exponential family, the user first needs to specify projection parameters:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.ProjectionParameters" href="#ExponentialFamilyProjection.ProjectionParameters"><code>ExponentialFamilyProjection.ProjectionParameters</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ProjectionParameters(; kwargs...)</code></pre><p>A type to hold the parameters for the projection procedure.  The following parameters are available:</p><ul><li><code>strategy = ExponentialFamilyProjection.DefaultStrategy()</code>: The strategy to use to compute the gradients.</li><li><code>niterations = 100</code>: The number of iterations for the optimization procedure.</li><li><code>tolerance = 1e-6</code>: The tolerance for the norm of the gradient.</li><li><code>stepsize = ConstantLength(0.1)</code>: The stepsize for the optimization procedure. Accepts stepsizes from <code>Manopt.jl</code>.</li><li><code>seed</code>: Optional; Seed for the <code>rng</code></li><li><code>rng</code>: Optional; Random number generator</li><li><code>direction = BoundedNormUpdateRule(static(1.0)</code>: Direction update rule. Accepts <code>Manopt.DirectionUpdateRule</code> from <code>Manopt.jl</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/projected_to.jl#L102-L115">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.DefaultProjectionParameters" href="#ExponentialFamilyProjection.DefaultProjectionParameters"><code>ExponentialFamilyProjection.DefaultProjectionParameters</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DefaultProjectionParameters()</code></pre><p>Return the default parameters for the projection procedure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/projected_to.jl#L126-L130">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.getinitialpoint" href="#ExponentialFamilyProjection.getinitialpoint"><code>ExponentialFamilyProjection.getinitialpoint</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">getinitialpoint(strategy, M::AbstractManifold, parameters::ProjectionParameters)</code></pre><p>Returns an initial point to start optimization from. By default returns a <code>rand</code> point from <code>M</code>,  but different strategies may implement their own methods.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/projected_to.jl#L141-L146">source</a></section></article><p>Read more about different optimization strategies <a href="#opt-strategies">here</a>.</p><h2 id="Projection-family"><a class="docs-heading-anchor" href="#Projection-family">Projection family</a><a id="Projection-family-1"></a><a class="docs-heading-anchor-permalink" href="#Projection-family" title="Permalink"></a></h2><p>After the parameters have been specified the user can proceed with specifying the projection type (exponential family member), its dimensionality and (optionally) the conditioner.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.ProjectedTo" href="#ExponentialFamilyProjection.ProjectedTo"><code>ExponentialFamilyProjection.ProjectedTo</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ProjectedTo(::Type{T}, dims...; conditioner = nothing, parameters = DefaultProjectionParameters)</code></pre><p>A specification of a projection to an exponential family distribution.</p><p>The following arguments are required:</p><ul><li><code>Type{T}</code>: a type of an exponential family member to project to, e.g. <code>Beta</code></li><li><code>dims...</code>: dimensions of the distribution, e.g. <code>2</code> for <code>MvNormal</code></li></ul><p>The following arguments are optional:</p><ul><li><code>conditioner = nothing</code>: a conditioner to use for the projection, not all exponential family members require a conditioner, but some do, e.g. <code>Laplace</code></li><li><code>parameters = DefaultProjectionParameters</code>: parameters for the projection procedure</li><li><code>kwargs = nothing</code>: Additional arguments passed to <code>Manopt.gradient_descent!</code> (optional). For details on <code>gradient_descent!</code> parameters, see the <a href="https://manoptjl.org/stable/solvers/gradient_descent/#Manopt.gradient_descent">Manopt.jl documentation</a>. Note, that <code>kwargs</code> passed to <code>project_to</code> take precedence over <code>kwargs</code> specified in the parameters.</li></ul><pre><code class="language-julia-repl hljs">julia&gt; using ExponentialFamily

julia&gt; projected_to = ProjectedTo(Beta)
ProjectedTo(Beta)

julia&gt; projected_to = ProjectedTo(Beta, parameters = ProjectionParameters(niterations = 10))
ProjectedTo(Beta)

julia&gt; projected_to = ProjectedTo(MvNormalMeanCovariance, 2)
ProjectedTo(MvNormalMeanCovariance, dims = 2)

julia&gt; projected_to = ProjectedTo(Laplace, conditioner = 2.0)
ProjectedTo(Laplace, conditioner = 2.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/projected_to.jl#L5-L36">source</a></section></article><h2 id="Projection"><a class="docs-heading-anchor" href="#Projection">Projection</a><a id="Projection-1"></a><a class="docs-heading-anchor-permalink" href="#Projection" title="Permalink"></a></h2><p>The projection is performed by calling the <code>project_to</code> function with the specified <a href="#ExponentialFamilyProjection.ProjectedTo"><code>ExponentialFamilyProjection.ProjectedTo</code></a> and log probability density function or a set of data point as the second argument.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.project_to" href="#ExponentialFamilyProjection.project_to"><code>ExponentialFamilyProjection.project_to</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">project_to(to::ProjectedTo, argument::F, supplementary..., initialpoint, kwargs...)</code></pre><p>Finds the closest projection of <code>argument</code> onto the exponential family distribution specified by <code>to</code>.</p><p><strong>Arguments</strong></p><ul><li><code>to::ProjectedTo</code>: Configuration for the projection. Refer to <code>ProjectedTo</code> for detailed information.</li><li><code>argument::F</code>: An (un-normalized) function representing the log-PDF of an arbitrary distribution <em>or</em> a list of samples.</li><li><code>supplementary...</code>: Additional distributions to project the product of <code>argument</code> and these distributions (optional).</li><li><code>initialpoint</code>: Starting point for the optimization process (optional).</li><li><code>kwargs...</code>: Additional arguments passed to <code>Manopt.gradient_descent!</code> (optional). For details on <code>gradient_descent!</code> parameters, see the <a href="https://manoptjl.org/stable/solvers/gradient_descent/#Manopt.gradient_descent">Manopt.jl documentation</a>.</li></ul><p><strong>Supplementary</strong></p><p>The <code>supplementary</code> distributions must match the type and conditioner of the target distribution specified in <code>to</code>.  Including supplementary distributions is equivalent to modified <code>argument</code> function as follows:</p><pre><code class="language-julia hljs">f_modified = (x) -&gt; argument(x) + logpdf(supplementary[1], x) + logpdf(supplementary[2], x) + ...</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using ExponentialFamily, BayesBase

julia&gt; f = (x) -&gt; logpdf(Beta(30.14, 2.71), x);

julia&gt; prj = ProjectedTo(Beta; parameters = ProjectionParameters(niterations = 500))
ProjectedTo(Beta)

julia&gt; project_to(prj, f) isa ExponentialFamily.Beta
true</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using ExponentialFamily, BayesBase, StableRNGs

julia&gt; samples = rand(StableRNG(42), Beta(30.14, 2.71), 1_000);

julia&gt; prj = ProjectedTo(Beta; parameters = ProjectionParameters(tolerance = 1e-2))
ProjectedTo(Beta)

julia&gt; project_to(prj, samples) isa ExponentialFamily.Beta
true</code></pre><div class="admonition is-info" id="Note-c162c0d85a630998"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-c162c0d85a630998" title="Permalink"></a></header><div class="admonition-body"><p>Different strategies are compatible with different types of arguments. Read optimization strategies section in the documentation for more information.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/projected_to.jl#L195-L242">source</a></section></article><h2 id="opt-strategies"><a class="docs-heading-anchor" href="#opt-strategies">Optimization strategies</a><a id="opt-strategies-1"></a><a class="docs-heading-anchor-permalink" href="#opt-strategies" title="Permalink"></a></h2><p>The optimization procedure requires computing the expectation of the gradient to perform gradient descent in the natural parameters space. Currently, the library provides the following strategies for computing these expectations:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.DefaultStrategy" href="#ExponentialFamilyProjection.DefaultStrategy"><code>ExponentialFamilyProjection.DefaultStrategy</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DefaultStrategy</code></pre><p>The DefaultStrategy selects the optimal projection strategy based on the type of the second argument provided to the <code>project_to</code> function.</p><p>Rules:</p><ul><li>If the second argument is an <code>AbstractArray</code>, use <code>MLEStrategy</code>.</li><li>For all other types, use <code>ControlVariateStrategy</code>.</li></ul><div class="admonition is-info" id="Note-9a5807e0ed21d9a9"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-9a5807e0ed21d9a9" title="Permalink"></a></header><div class="admonition-body"><p>The rules above are subject to change.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/default.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.ControlVariateStrategy" href="#ExponentialFamilyProjection.ControlVariateStrategy"><code>ExponentialFamilyProjection.ControlVariateStrategy</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ControlVariateStrategy(; kwargs...)</code></pre><p>A strategy for gradient descent optimization and gradients computations that resembles the REINFORCE gradient estimator.</p><p>The following parameters are available:</p><ul><li><code>nsamples = 2000</code>: The number of samples to use for estimates</li><li><code>buffer = Bumper.SlabBuffer()</code>: Advanced option; A buffer for temporary computations</li></ul><div class="admonition is-info" id="Note-efc9468131f13907"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-efc9468131f13907" title="Permalink"></a></header><div class="admonition-body"><p>This strategy requires a function as an argument for <code>project_to</code> and cannot project a collection of samples. Use <code>MLEStrategy</code> to project a collection of samples.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/control_variate.jl#L6-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.MLEStrategy" href="#ExponentialFamilyProjection.MLEStrategy"><code>ExponentialFamilyProjection.MLEStrategy</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MLEStrategy()</code></pre><p>A strategy for gradient descent optimization and gradients computations that resembles MLE estimation.</p><div class="admonition is-info" id="Note-ff383a672b57b1ad"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-ff383a672b57b1ad" title="Permalink"></a></header><div class="admonition-body"><p>This strategy requires a collection of samples as an argument for <code>project_to</code> and cannot project a function. Use <code>ControlVariateStrategy</code> to project a function.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/mle.jl#L2-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.BonnetStrategy" href="#ExponentialFamilyProjection.BonnetStrategy"><code>ExponentialFamilyProjection.BonnetStrategy</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BonnetStrategy{S, TL}</code></pre><p>A strategy for gradient descent optimization and gradients computations that resembles the Bonnet gradient estimator that works for normal distributions. It&#39;s based on the equations (10) and (11) in <a href="https://arxiv.org/pdf/2107.04562">Khan, 2024</a>.</p><p>The following parameters are available:</p><ul><li><code>nsamples = 2000</code>: The number of samples to use for estimates</li></ul><div class="admonition is-info" id="Note-c2dcc448e763df52"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-c2dcc448e763df52" title="Permalink"></a></header><div class="admonition-body"><p>This strategy requires a function as an argument for <code>project_to</code> and cannot project a collection of samples. Use <code>MLEStrategy</code> to project a collection of samples. This strategy requires a logpdf function that can be converted to an <code>InplaceLogpdfGradHess</code> object. This strategy requires the normal manifold.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/strategy.jl#L5-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.GaussNewton" href="#ExponentialFamilyProjection.GaussNewton"><code>ExponentialFamilyProjection.GaussNewton</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GaussNewton{S,TL}</code></pre><p>A deterministic strategy that resembles the Bonnet gradient with a point-mass approximation (no sampling). For normal distributions, it evaluates logpdf/grad/Hessian once at the current mean and takes a step. It implements the update akin to Eq. (13) in <a href="https://arxiv.org/pdf/2107.04562">Khan, 2024</a>.</p><div class="admonition is-info" id="Note-c2dcc448e763df52"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-c2dcc448e763df52" title="Permalink"></a></header><div class="admonition-body"><p>This strategy requires a function as an argument for <code>project_to</code> and cannot project a collection of samples. Use <code>MLEStrategy</code> to project a collection of samples. This strategy requires a logpdf function that can be converted to an <code>InplaceLogpdfGradHess</code> object. This strategy requires the normal manifold.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/gauss_newton.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.preprocess_strategy_argument" href="#ExponentialFamilyProjection.preprocess_strategy_argument"><code>ExponentialFamilyProjection.preprocess_strategy_argument</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">preprocess_strategy_argument(strategy, argument)</code></pre><p>Checks the compatibility of <code>strategy</code> with <code>argument</code> and returns a modified strategy and argument if needed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/ExponentialFamilyProjection.jl#L31-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.create_state!" href="#ExponentialFamilyProjection.create_state!"><code>ExponentialFamilyProjection.create_state!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">create_state!(
    strategy,
    M::AbstractManifold,
    parameters::ProjectionParameters,
    projection_argument,
    initial_ef,
    supplementary_η,
)</code></pre><p>Creates, initializes and returns a state for the <code>strategy</code> with the given parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/ExponentialFamilyProjection.jl#L38-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.prepare_state!" href="#ExponentialFamilyProjection.prepare_state!"><code>ExponentialFamilyProjection.prepare_state!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">prepare_state!(
    strategy,
    state,
    M::AbstractManifold,
    parameters::ProjectionParameters,
    projection_argument,
    distribution,
    supplementary_η,
)</code></pre><p>Prepares an existing <code>state</code> of the <code>strategy</code> for the new optimization iteration for use by setting or updating its internal parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/ExponentialFamilyProjection.jl#L52-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.compute_cost" href="#ExponentialFamilyProjection.compute_cost"><code>ExponentialFamilyProjection.compute_cost</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">compute_cost(
    M::AbstractManifold,
    strategy,
    state,
    η,
    logpartition,
    gradlogpartition,
    inv_fisher,
)</code></pre><p>Compute the cost using the provided <code>strategy</code>.</p><p><strong>Arguments</strong></p><ul><li><code>M::AbstractManifold</code>: The manifold on which the computations are performed.</li><li><code>strategy</code>: The strategy used for computation of the cost value.</li><li><code>state</code>: The current state for the <code>strategy</code>.</li><li><code>η</code>: Parameter vector.</li><li><code>logpartition</code>: The log partition of the current point (η).</li><li><code>gradlogpartition</code>: The gradient of the log partition of the current point (η).</li><li><code>inv_fisher</code>: The inverse Fisher information matrix of the current point (η).</li></ul><p><strong>Returns</strong></p><ul><li><code>cost</code>: The computed cost value.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/ExponentialFamilyProjection.jl#L67-L91">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.compute_gradient!" href="#ExponentialFamilyProjection.compute_gradient!"><code>ExponentialFamilyProjection.compute_gradient!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">compute_gradient!(
    M::AbstractManifold,
    strategy,
    state,
    X,
    η,
    logpartition,
    gradlogpartition,
    inv_fisher,
)</code></pre><p>Updates the gradient <code>X</code> in-place using the provided <code>strategy</code>.</p><p><strong>Arguments</strong></p><ul><li><code>M::AbstractManifold</code>: The manifold on which the computations are performed.</li><li><code>strategy</code>: The strategy used for computation of the gradient value.</li><li><code>state</code>: The current state of the control variate strategy.</li><li><code>X</code>: The storage for the gradient.</li><li><code>η</code>: Parameter vector.</li><li><code>logpartition</code>: The log partition of the current point (η).</li><li><code>gradlogpartition</code>: The gradient of the log partition of the current point (η).</li><li><code>inv_fisher</code>: The inverse Fisher information matrix of the current point (η).</li></ul><p><strong>Returns</strong></p><ul><li><code>X</code>: The computed gradient (updated in-place)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/ExponentialFamilyProjection.jl#L94-L120">source</a></section></article><h2 id="In-place-logpdf/grad/Hessian-adapters"><a class="docs-heading-anchor" href="#In-place-logpdf/grad/Hessian-adapters">In-place logpdf/grad/Hessian adapters</a><a id="In-place-logpdf/grad/Hessian-adapters-1"></a><a class="docs-heading-anchor-permalink" href="#In-place-logpdf/grad/Hessian-adapters" title="Permalink"></a></h2><p>The library provides convenient wrappers to evaluate log-density, gradient, and Hessian in-place, and an adapter to combine separate <code>grad!</code>/<code>hess!</code> into a single <code>grad_hess!</code>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.InplaceLogpdfGradHess" href="#ExponentialFamilyProjection.InplaceLogpdfGradHess"><code>ExponentialFamilyProjection.InplaceLogpdfGradHess</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">InplaceLogpdfGradHess(logpdf!, grad_hess!)</code></pre><p>Wraps <code>logpdf!</code> and the unified <code>grad_hess!</code> function in a type used for dispatch. The unified interface evaluates gradient and Hessian together for efficiency.</p><p><strong>Arguments</strong></p><ul><li><code>logpdf!</code>: Function that takes <code>(out_logpdf, x)</code> and writes the logpdf to <code>out_logpdf</code></li><li><code>grad_hess!</code>: Function that takes <code>(out_grad, out_hess, x)</code> and writes gradient and Hessian</li></ul><p><strong>Methods</strong></p><ul><li><code>logpdf!(structure, out, x)</code></li><li><code>grad_hess!(structure, out_grad, out_hess, x)</code></li></ul><p>All methods expect pre-allocated containers of appropriate dimensions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/bonnet_logpdf.jl#L2-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.InplaceLogpdfGradHess-Tuple{Any, Any, Any}" href="#ExponentialFamilyProjection.InplaceLogpdfGradHess-Tuple{Any, Any, Any}"><code>ExponentialFamilyProjection.InplaceLogpdfGradHess</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">InplaceLogpdfGradHess(logpdf!, grad!, hess!)</code></pre><p>Outer convenience constructor that accepts separate <code>grad!</code> and <code>hess!</code> functions. Internally it wraps them with <code>NaiveGradHess</code> to provide a unified <code>grad_hess!</code> implementation and returns an <code>InplaceLogpdfGradHess</code> instance.</p><p><strong>Arguments</strong></p><ul><li><code>logpdf!</code>: Function <code>(out_logpdf, x) -&gt;</code> writes the log-density into <code>out_logpdf</code></li><li><code>grad!</code>: Function <code>(out_grad, x) -&gt;</code> writes the gradient into <code>out_grad</code></li><li><code>hess!</code>: Function <code>(out_hess, x) -&gt;</code> writes the Hessian into <code>out_hess</code></li></ul><p><strong>See also</strong></p><ul><li><code>NaiveGradHess</code> — adapter that combines separate <code>grad!</code>/<code>hess!</code> into <code>grad_hess!</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/bonnet_logpdf.jl#L23-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.NaiveGradHess" href="#ExponentialFamilyProjection.NaiveGradHess"><code>ExponentialFamilyProjection.NaiveGradHess</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NaiveGradHess{G, H}</code></pre><p>Adapter that exposes only <code>grad_hess!</code> by calling provided <code>grad!</code> and <code>hess!</code> sequentially. Useful as a fallback when a combined implementation is not available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/naive_grad_hess.jl#L1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.logpdf!-Tuple{ExponentialFamilyProjection.InplaceLogpdfGradHess, Any, Any}" href="#ExponentialFamilyProjection.logpdf!-Tuple{ExponentialFamilyProjection.InplaceLogpdfGradHess, Any, Any}"><code>ExponentialFamilyProjection.logpdf!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">logpdf!(inplace::InplaceLogpdfGradHess, out, x)</code></pre><p>Evaluate the log probability density function at point <code>x</code>, writing the result to pre-allocated container <code>out</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/bonnet_logpdf.jl#L43-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.grad_hess!-Tuple{ExponentialFamilyProjection.InplaceLogpdfGradHess, Any, Any, Any}" href="#ExponentialFamilyProjection.grad_hess!-Tuple{ExponentialFamilyProjection.InplaceLogpdfGradHess, Any, Any, Any}"><code>ExponentialFamilyProjection.grad_hess!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">grad_hess!(inplace::InplaceLogpdfGradHess, out_grad, out_hess, x)</code></pre><p>Evaluate the gradient and the Hessian at point <code>x</code>, writing the result to pre-allocated containers <code>out_grad</code> and <code>out_hess</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/bonnet_logpdf.jl#L53-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.grad_hess!-Tuple{ExponentialFamilyProjection.NaiveGradHess, Any, Any, Any}" href="#ExponentialFamilyProjection.grad_hess!-Tuple{ExponentialFamilyProjection.NaiveGradHess, Any, Any, Any}"><code>ExponentialFamilyProjection.grad_hess!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">grad_hess!(inplace::NaiveGradHess, out_grad, out_hess, x)</code></pre><p>Evaluate the gradient and the Hessian at point <code>x</code> using the provided separate implementations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/strategies/bonnet/naive_grad_hess.jl#L12-L16">source</a></section></article><p>For high-dimensional distributions, adjusting the default number of samples might be necessary to achieve better performance.</p><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><h3 id="Gaussian-projection"><a class="docs-heading-anchor" href="#Gaussian-projection">Gaussian projection</a><a id="Gaussian-projection-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-projection" title="Permalink"></a></h3><p>In this example we project an arbitrary log probability density function onto a Gaussian distribution. The log probability density function is defined using another <code>Gaussian</code>, but it can be any function:</p><pre><code class="language-julia hljs">using ExponentialFamilyProjection, ExponentialFamily, BayesBase

hiddengaussian = NormalMeanVariance(3.14, 2.71)
targetf = (x) -&gt; logpdf(hiddengaussian, x)
prj = ProjectedTo(NormalMeanVariance)
result = project_to(prj, targetf)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ExponentialFamily.NormalMeanVariance{Float64}(μ=3.147287071387545, v=2.6741746757950247)</code></pre><p>We can see that the estimated <code>result</code> is pretty close to the actual <code>hiddengaussian</code> used to define the <code>targetf</code>. We can also visualise the results using the <code>Plots.jl</code> package.</p><pre><code class="language-julia hljs">using Plots

plot(-6.0:0.1:12.0, x -&gt; pdf(hiddengaussian, x), label=&quot;real distribution&quot;, fill = 0, fillalpha = 0.2)
plot!(-6.0:0.1:12.0, x -&gt; pdf(result, x), label=&quot;estimated projection&quot;, fill = 0, fillalpha = 0.2)</code></pre><img src="index-e6362c47.svg" alt="Example block output"/><p>Let&#39;s also try to project an arbitrary unnormalized log probability density function onto a Gaussian distribution:</p><pre><code class="language-julia hljs"># `+ 100` to ensure that the function is unnormalized
targetf = (x) -&gt; -0.5 * (x - 3.14)^2 + 100

result = project_to(prj, targetf)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ExponentialFamily.NormalMeanVariance{Float64}(μ=3.022854932263283, v=0.8218806444470579)</code></pre><p>In this case, <code>targetf</code> does not define any valid probability distribution since it is unnormalized, but the <code>project_to</code> function is able to project it onto a closest possible Gaussian distribution. We can again visualize the results using the <code>Plots.jl</code> package:</p><pre><code class="language-julia hljs">plot(-40.0:0.1:40.0, targetf, label=&quot;unnormalized logpdf&quot;, fill = 0, fillalpha = 0.2)
plot!(-40.0:0.1:40.0, (x) -&gt; logpdf(result, x), label=&quot;estimated logpdf of a Gaussian&quot;, fill = 0, fillalpha = 0.2)</code></pre><img src="index-dbeaaead.svg" alt="Example block output"/><h3 id="Beta-projection"><a class="docs-heading-anchor" href="#Beta-projection">Beta projection</a><a id="Beta-projection-1"></a><a class="docs-heading-anchor-permalink" href="#Beta-projection" title="Permalink"></a></h3><p>The experiment can be performed for other members of the exponential family as well. For example, let&#39;s project an arbitrary log probability density function onto a Beta distribution:</p><pre><code class="language-julia hljs">hiddenbeta = Beta(10, 3)
targetf = (x) -&gt; logpdf(hiddenbeta, x)
prj = ProjectedTo(Beta)
result = project_to(prj, targetf)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Distributions.Beta{Float64}(α=8.97671074447669, β=2.7316968890241995)</code></pre><p>And let&#39;s visualize the result using the <code>Plots.jl</code> package:</p><pre><code class="language-julia hljs">plot(0.0:0.01:1.0, x -&gt; pdf(hiddenbeta, x), label=&quot;real distribution&quot;, fill = 0, fillalpha = 0.2)
plot!(0.0:0.01:1.0, x -&gt; pdf(result, x), label=&quot;estimated projection&quot;, fill = 0, fillalpha = 0.2)</code></pre><img src="index-39d9deaa.svg" alt="Example block output"/><h3 id="Multivariate-Gaussian-projection"><a class="docs-heading-anchor" href="#Multivariate-Gaussian-projection">Multivariate Gaussian projection</a><a id="Multivariate-Gaussian-projection-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-Gaussian-projection" title="Permalink"></a></h3><p>The library also supports multivariate distributions. Let&#39;s project an arbitrary log probability density function onto a multivariate Gaussian distribution.</p><pre><code class="language-julia hljs">hiddengaussian = MvNormalMeanCovariance(
    [ 3.14, 2.17 ],
    [ 2.0 -0.1; -0.1 3.0 ]
)
targetf = (x) -&gt; logpdf(hiddengaussian, x)
prj = ProjectedTo(MvNormalMeanCovariance, 2)
result = project_to(prj, targetf)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MvNormalMeanCovariance(
μ: [3.046220659005711, 2.215291316607296]
Σ: [1.8986008425872856 0.002457042029684182; 0.002457042029684182 2.9753353173865795]
)
</code></pre><p>As in previous examples the result is pretty close to the actual <code>hiddengaussian</code> used to define the <code>targetf</code>. </p><h3 id="Gauss–Newton-strategy-(logistic-regression)"><a class="docs-heading-anchor" href="#Gauss–Newton-strategy-(logistic-regression)">Gauss–Newton strategy (logistic regression)</a><a id="Gauss–Newton-strategy-(logistic-regression)-1"></a><a class="docs-heading-anchor-permalink" href="#Gauss–Newton-strategy-(logistic-regression)" title="Permalink"></a></h3><p>The Gauss–Newton strategy uses first and second derivatives of the target log-density to form a deterministic update, avoiding Monte Carlo sampling. This is useful when you can provide in-place <code>logpdf!</code>, <code>grad!</code>, and <code>hess!</code> for your target. Below we demonstrate projecting a Bayesian logistic regression model (which is not a normalized distribution) onto a multivariate Gaussian using Gauss–Newton strategy <code>GaussNewton</code>.</p><p>We split this example into small steps and use a shared example environment so that variables (including a stable RNG) persist between blocks.</p><p>In the following block we sample <code>X</code> (our features) and <code>y</code> (binary outputs).</p><pre><code class="language-julia hljs">using LinearAlgebra
using StableRNGs
using Distributions
using ExponentialFamily
using ExponentialFamilyProjection
using Plots

# 1) Generate a reproducible dataset (shared RNG)
rng = StableRNG(42)
n = 600
input_dim = 2
d = input_dim + 1
X_feat = randn(rng, n, input_dim)
X = hcat(ones(n), X_feat)
β_true = [0.5, 2.0, -1.5]
σ(z) = 1 / (1 + exp(-z))
p = map(σ, X * β_true)
y = rand.(Ref(rng), Bernoulli.(p));</code></pre><p>We created a binary logistic regression dataset with an intercept and fixed <code>rng</code> for reproducibility.</p><pre><code class="language-julia hljs"># 2) Define in-place log-posterior, gradient, and Hessian
function logpost!(out::AbstractVector{T}, β::AbstractVector{T}) where {T&lt;:Real}
    Xβ = X * β
    @inline function log1pexp(z)
        z &gt; 0 ? z + log1p(exp(-z)) : log1p(exp(z))
    end
    s = zero(T)
    @inbounds for i in 1:n
        s += y[i] * Xβ[i] - log1pexp(Xβ[i])
    end
    # standard normal prior on β
    s += -0.5 * dot(β, β)
    out[1] = s
    return out
end

function grad!(out::AbstractVector{T}, β::AbstractVector{T}) where {T&lt;:Real}
    fill!(out, 0)
    Xβ = X * β
    @inbounds for i in 1:n
        pi = 1 / (1 + exp(-Xβ[i]))
        @views out[:] .+= (y[i] - pi) .* X[i, :]
    end
    return out
end

function hess!(out::AbstractMatrix{T}, β::AbstractVector{T}) where {T&lt;:Real}
    Xβ = X * β
    fill!(out, 0)
    @inbounds for i in 1:n
        pi = 1 / (1 + exp(-Xβ[i]))
        wi = pi * (1 - pi)
        @views out .-= wi .* (X[i, :] * transpose(X[i, :]))
    end
    return out
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">hess! (generic function with 1 method)</code></pre><p>These in-place routines allow Gauss–Newton to form deterministic updates without Monte Carlo sampling.</p><pre><code class="language-julia hljs"># 3) Wrap and run Gauss–Newton projection
inplace = ExponentialFamilyProjection.InplaceLogpdfGradHess(logpost!, grad!, hess!)
params = ProjectionParameters(
    tolerance = 1e-8,
    strategy = ExponentialFamilyProjection.GaussNewton(nsamples = 1), # deterministic
)
prj = ProjectedTo(MvNormalMeanCovariance, d; parameters = params)
result = project_to(prj, inplace)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MvNormalMeanCovariance(
μ: [0.1899735085900649, 0.8944230856095603, -0.48689068986755923]
Σ: [0.09654291677579087 0.00036433306504875685 0.0027047450407188234; 0.00036433306504875685 0.10658332461101037 -0.01129930001921165; 0.0027047450407188234 -0.01129930001921165 0.09522152710566681]
)
</code></pre><p>This projects the posterior to an <code>MvNormalMeanCovariance</code> parameterization using Gauss–Newton updates.</p><pre><code class="language-julia hljs"># 4) Inspect the projection result
μ = mean(result)
Σ = cov(result)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.1899735085900649, 0.8944230856095603, -0.48689068986755923], (3, 3))</code></pre><p>Now we visualize the posterior-mean decision boundary and probability map. We compute a grid over feature space and evaluate the mean prediction σ(μ₀ + μ₁ x₁ + μ₂ x₂).</p><pre><code class="language-julia hljs"># 5) Build grid and compute posterior-mean probabilities
x1_min = minimum(X[:, 2]) - 3.0
x1_max = maximum(X[:, 2]) + 3.0
x2_min = minimum(X[:, 3]) - 3.0
x2_max = maximum(X[:, 3]) + 3.0

xs = range(x1_min, x1_max; length = 200)
ys = range(x2_min, x2_max; length = 200)
Z = Array{Float64}(undef, length(xs), length(ys))
for (i, x1) in enumerate(xs)
    for (j, x2) in enumerate(ys)
        z = μ[1] + μ[2] * x1 + μ[3] * x2
        Z[i, j] = 1.0 / (1.0 + exp(-z))
    end
end</code></pre><pre><code class="language-julia hljs"># 6) Render probability heatmap and 0.5 decision contour with data overlay
plt_mean = contourf(
    xs, ys, Z&#39;;
    levels = 0:0.05:1,
    c = cgrad([:red, :green]),
    alpha = 0.65,
    colorbar_title = &quot;P(y=1)&quot;,
    contour_lines = false,
    linecolor = :transparent,
    linewidth = 0,
    size = (650, 500),
)
contour!(xs, ys, Z&#39;; levels = [0.5], linecolor = :black, linewidth = 3, label = nothing)
scatter!(
    X[y .== 0, 2], X[y .== 0, 3];
    markersize = 6,
    markerstrokecolor = :white,
    markerstrokewidth = 0.8,
    label = &quot;y = 0&quot;,
    color = :red4,
)
scatter!(
    X[y .== 1, 2], X[y .== 1, 3];
    markersize = 6,
    markerstrokecolor = :white,
    markerstrokewidth = 0.8,
    label = &quot;y = 1&quot;,
    color = :green4,
)
xlabel!(&quot;x₁&quot;)
ylabel!(&quot;x₂&quot;)
title!(&quot;mean boundary&quot;)</code></pre><img src="index-8806de67.svg" alt="Example block output"/><p>To account for parameter uncertainty, we can estimate the predictive probability by Monte Carlo: sample coefficients β from the Gaussian posterior <code>result ~ N(μ, Σ)</code> and average σ(β₀ + β₁ x₁ + β₂ x₂) over samples. This yields a boundary reflecting posterior spread.</p><pre><code class="language-julia hljs"># 7) Monte Carlo-averaged predictive map from posterior β ~ N(μ, Σ)
nsamples_pred = 200
Zmc = zeros(length(xs), length(ys))
mvn_post = MvNormal(μ, Symmetric(Σ))
for s in 1:nsamples_pred
    βs = rand(rng, mvn_post)
    for (i, x1) in enumerate(xs)
        for (j, x2) in enumerate(ys)
            z = βs[1] + βs[2] * x1 + βs[3] * x2
            Zmc[i, j] += 1.0 / (1.0 + exp(-z))
        end
    end
end
Zmc ./= nsamples_pred</code></pre><pre><code class="language-julia hljs"># 8) Render MC-averaged probability heatmap and decision contour
plt_mc = contourf(
    xs, ys, Zmc&#39;;
    levels = 0:0.05:1,
    c = cgrad([:red, :green]),
    alpha = 0.65,
    colorbar_title = &quot;E[P(y=1)]&quot;,
    contour_lines = false,
    linecolor = :transparent,
    linewidth = 0,
    size = (650, 500),
)
contour!(xs, ys, Zmc&#39;; levels = [0.5], linecolor = :black, linewidth = 3, label = nothing)
scatter!(
    X[y .== 0, 2], X[y .== 0, 3];
    markersize = 6,
    markerstrokecolor = :white,
    markerstrokewidth = 0.8,
    label = &quot;y = 0&quot;,
    color = :red4,
)
scatter!(
    X[y .== 1, 2], X[y .== 1, 3];
    markersize = 6,
    markerstrokecolor = :white,
    markerstrokewidth = 0.8,
    label = &quot;y = 1&quot;,
    color = :green4,
)
xlabel!(&quot;x₁&quot;)
ylabel!(&quot;x₂&quot;)
title!(&quot;full posterior boundary&quot;)
plt_mc</code></pre><img src="index-0e391293.svg" alt="Example block output"/><pre><code class="language-julia hljs"># 9) Optional: side-by-side comparison
plot(plt_mean, plt_mc; layout = (1, 2), size = (1100, 450))</code></pre><img src="index-763535f8.svg" alt="Example block output"/><h3 id="Projection-with-samples"><a class="docs-heading-anchor" href="#Projection-with-samples">Projection with samples</a><a id="Projection-with-samples-1"></a><a class="docs-heading-anchor-permalink" href="#Projection-with-samples" title="Permalink"></a></h3><p>The projection can be done given a set of samples instead of the function directly. For example, let&#39;s project an set of samples onto a Beta distribution:</p><pre><code class="language-julia hljs">using StableRNGs

hiddenbeta = Beta(10, 3)
samples = rand(StableRNG(42), hiddenbeta, 1_000)
prj = ProjectedTo(Beta)
result = project_to(prj, samples)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Distributions.Beta{Float64}(α=9.934683749459355, β=2.844620239774742)</code></pre><pre><code class="language-julia hljs">plot(0.0:0.01:1.0, x -&gt; pdf(hiddenbeta, x), label=&quot;real distribution&quot;, fill = 0, fillalpha = 0.2)
histogram!(samples, label = &quot;samples&quot;, normalize = :pdf, fillalpha = 0.2)
plot!(0.0:0.01:1.0, x -&gt; pdf(result, x), label=&quot;estimated projection&quot;, fill = 0, fillalpha = 0.2)</code></pre><img src="index-8acca1d0.svg" alt="Example block output"/><h2 id="Other"><a class="docs-heading-anchor" href="#Other">Other</a><a id="Other-1"></a><a class="docs-heading-anchor-permalink" href="#Other" title="Permalink"></a></h2><h2 id="Manopt-extensions"><a class="docs-heading-anchor" href="#Manopt-extensions">Manopt extensions</a><a id="Manopt-extensions-1"></a><a class="docs-heading-anchor-permalink" href="#Manopt-extensions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.ProjectionCostGradientObjective" href="#ExponentialFamilyProjection.ProjectionCostGradientObjective"><code>ExponentialFamilyProjection.ProjectionCostGradientObjective</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ProjectionCostGradientObjective</code></pre><p>This structure provides an interface for <code>Manopt</code> to compute the cost and gradients required for the optimization procedure based on manifold projection. The actual computation of costs and gradients is defined by the <code>strategy</code> argument.</p><p><strong>Arguments</strong></p><ul><li><code>projection_parameters</code>: The parameters for projection, must be of type <code>ProjectionParameters</code></li><li><code>projection_argument</code>: The second argument of the <code>project_to</code> function.</li><li><code>current_η</code>: Current optimization point.</li><li><code>supplementary_η</code>: A tuple of additional natural parameters subtracted from the current point in each optimization iteration.</li><li><code>strategy</code>: Specifies the method for computing costs and gradients, which may support different <code>projection_argument</code> values.</li><li><code>strategy_state</code>: The state for the <code>strategy</code>, usually created with <code>create_state!</code></li></ul><div class="admonition is-info" id="Note-66e23b31178a2435"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-66e23b31178a2435" title="Permalink"></a></header><div class="admonition-body"><p>This structure is internal and is subject to change.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/manopt/projection_objective.jl#L1-L17">source</a></section></article><h3 id="Bounded-direction-update-rule"><a class="docs-heading-anchor" href="#Bounded-direction-update-rule">Bounded direction update rule</a><a id="Bounded-direction-update-rule-1"></a><a class="docs-heading-anchor-permalink" href="#Bounded-direction-update-rule" title="Permalink"></a></h3><p>The <code>ExponentialFamilyProjection.jl</code> package implements a specialized gradient direction rule that limits the norm (manifold-specific) of the gradient to a pre-specified value.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ExponentialFamilyProjection.BoundedNormUpdateRule" href="#ExponentialFamilyProjection.BoundedNormUpdateRule"><code>ExponentialFamilyProjection.BoundedNormUpdateRule</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BoundedNormUpdateRule(limit; direction = Manopt.IdentityUpdateRule())</code></pre><p>A <code>DirectionUpdateRule</code> is a direction rule that constrains the norm of the direction to a specified limit.</p><p>This rule operates in two steps:</p><ul><li>Initial direction computation: It first applies the specified <code>direction</code> update rule to compute an initial direction.</li><li>Norm check and scaling: The norm of the resulting direction vector is checked using <code>Manopt.norm(M, p, d)</code>, where:<ul><li><code>M</code>` is the manifold on which the optimization is running,</li><li><code>p</code> is the point at which the direction was computed,</li><li><code>d</code> is the computed direction.</li><li>If this norm exceeds the specified <code>limit</code>, the direction vector is scaled down so that its new norm exactly equals the limit. This scaling preserves the direction of the gradient while controlling its magnitude.</li></ul></li></ul><p>Read more about <code>Manopt.DirectionUpdateRule</code> in the <code>Manopt.jl</code> documentation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/ExponentialFamilyProjection.jl/blob/cb0fae9c9c9316fdf4a2ed42087a1a2585153e00/src/manopt/bounded_norm_update_rule.jl#L3-L18">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#ExponentialFamilyProjection.BonnetStrategy"><code>ExponentialFamilyProjection.BonnetStrategy</code></a></li><li><a href="#ExponentialFamilyProjection.BoundedNormUpdateRule"><code>ExponentialFamilyProjection.BoundedNormUpdateRule</code></a></li><li><a href="#ExponentialFamilyProjection.ControlVariateStrategy"><code>ExponentialFamilyProjection.ControlVariateStrategy</code></a></li><li><a href="#ExponentialFamilyProjection.DefaultStrategy"><code>ExponentialFamilyProjection.DefaultStrategy</code></a></li><li><a href="#ExponentialFamilyProjection.GaussNewton"><code>ExponentialFamilyProjection.GaussNewton</code></a></li><li><a href="#ExponentialFamilyProjection.InplaceLogpdfGradHess"><code>ExponentialFamilyProjection.InplaceLogpdfGradHess</code></a></li><li><a href="#ExponentialFamilyProjection.InplaceLogpdfGradHess-Tuple{Any, Any, Any}"><code>ExponentialFamilyProjection.InplaceLogpdfGradHess</code></a></li><li><a href="#ExponentialFamilyProjection.MLEStrategy"><code>ExponentialFamilyProjection.MLEStrategy</code></a></li><li><a href="#ExponentialFamilyProjection.NaiveGradHess"><code>ExponentialFamilyProjection.NaiveGradHess</code></a></li><li><a href="#ExponentialFamilyProjection.ProjectedTo"><code>ExponentialFamilyProjection.ProjectedTo</code></a></li><li><a href="#ExponentialFamilyProjection.ProjectionCostGradientObjective"><code>ExponentialFamilyProjection.ProjectionCostGradientObjective</code></a></li><li><a href="#ExponentialFamilyProjection.ProjectionParameters"><code>ExponentialFamilyProjection.ProjectionParameters</code></a></li><li><a href="#ExponentialFamilyProjection.DefaultProjectionParameters"><code>ExponentialFamilyProjection.DefaultProjectionParameters</code></a></li><li><a href="#ExponentialFamilyProjection.compute_cost"><code>ExponentialFamilyProjection.compute_cost</code></a></li><li><a href="#ExponentialFamilyProjection.compute_gradient!"><code>ExponentialFamilyProjection.compute_gradient!</code></a></li><li><a href="#ExponentialFamilyProjection.create_state!"><code>ExponentialFamilyProjection.create_state!</code></a></li><li><a href="#ExponentialFamilyProjection.getinitialpoint"><code>ExponentialFamilyProjection.getinitialpoint</code></a></li><li><a href="#ExponentialFamilyProjection.grad_hess!-Tuple{ExponentialFamilyProjection.InplaceLogpdfGradHess, Any, Any, Any}"><code>ExponentialFamilyProjection.grad_hess!</code></a></li><li><a href="#ExponentialFamilyProjection.grad_hess!-Tuple{ExponentialFamilyProjection.NaiveGradHess, Any, Any, Any}"><code>ExponentialFamilyProjection.grad_hess!</code></a></li><li><a href="#ExponentialFamilyProjection.logpdf!-Tuple{ExponentialFamilyProjection.InplaceLogpdfGradHess, Any, Any}"><code>ExponentialFamilyProjection.logpdf!</code></a></li><li><a href="#ExponentialFamilyProjection.prepare_state!"><code>ExponentialFamilyProjection.prepare_state!</code></a></li><li><a href="#ExponentialFamilyProjection.preprocess_strategy_argument"><code>ExponentialFamilyProjection.preprocess_strategy_argument</code></a></li><li><a href="#ExponentialFamilyProjection.project_to"><code>ExponentialFamilyProjection.project_to</code></a></li></ul></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 21 October 2025 10:23">Tuesday 21 October 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
